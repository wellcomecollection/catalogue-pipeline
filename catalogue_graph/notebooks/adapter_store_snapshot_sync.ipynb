{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebf5d512",
   "metadata": {},
   "source": [
    "# Snapshot Sync Demonstration\n",
    "\n",
    "This notebook demonstrates the `snapshot_sync` method of `AdapterStore`, which synchronizes the table to match a complete snapshot of data.\n",
    "\n",
    "## Key Characteristics of snapshot_sync\n",
    "\n",
    "- **Full Synchronization**: Updates, inserts, AND deletes to match the snapshot exactly\n",
    "- **Soft Deletes**: Records missing from snapshot are marked with `content=None` (not physically removed)\n",
    "- **No Timestamp Checking**: Unlike `incremental_update`, snapshot_sync does NOT require or check timestamps for gating updates\n",
    "- **Timestamp Writing**: Does write `last_modified` timestamps to all changed records (auto-generated if not provided)\n",
    "- **Idempotent**: Applying the same snapshot twice produces no changes\n",
    "- **Namespace-Scoped**: Only affects records in the specified namespace\n",
    "\n",
    "**Use case**: Full harvests where you receive a complete dataset and want the table to match exactly (e.g., nightly full dumps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from uuid import uuid1\n",
    "import pyarrow as pa\n",
    "from adapters.utils.adapter_store import AdapterStore\n",
    "from adapters.utils.iceberg import get_local_table\n",
    "\n",
    "# Create a local Iceberg table for testing\n",
    "table_name = f\"demo_{str(uuid1())[:8]}\"\n",
    "table = get_local_table(\n",
    "    table_name=table_name,\n",
    "    namespace=\"demo\",\n",
    "    db_name=\"demo_catalog\",\n",
    ")\n",
    "store = AdapterStore(table, default_namespace=\"snapshot_namespace\")\n",
    "print(f\"Created table: {table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ede1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record_table(records: list[dict], namespace: str = \"snapshot_namespace\") -> pa.Table:\n",
    "    \"\"\"Create a PyArrow table from a list of records.\n",
    "    \n",
    "    Note: snapshot_sync does NOT require timestamps, but will auto-generate them if missing.\n",
    "    You can optionally provide last_modified values in records.\n",
    "    \"\"\"\n",
    "    for record in records:\n",
    "        record[\"namespace\"] = namespace\n",
    "    \n",
    "    # Basic schema without timestamps (snapshot_sync doesn't require them)\n",
    "    schema = pa.schema([\n",
    "        pa.field(\"namespace\", pa.string(), nullable=False),\n",
    "        pa.field(\"id\", pa.string(), nullable=False),\n",
    "        pa.field(\"content\", pa.string(), nullable=True),\n",
    "    ])\n",
    "    \n",
    "    return pa.Table.from_pylist(records, schema=schema)\n",
    "\n",
    "def display_table(title: str):\n",
    "    \"\"\"Display current table contents.\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(\"=\" * 100)\n",
    "    current = table.scan().to_arrow().sort_by(\"id\")\n",
    "    if current.num_rows == 0:\n",
    "        print(\"(empty table)\")\n",
    "    else:\n",
    "        df = current.to_pandas()\n",
    "        # Format for better readability\n",
    "        print(df.to_string(index=False))\n",
    "    return current\n",
    "\n",
    "def display_changeset_summary():\n",
    "    \"\"\"Display a summary of changesets in the table.\"\"\"\n",
    "    print(\"\\nüìä Changeset Summary\")\n",
    "    print(\"=\" * 100)\n",
    "    current = table.scan().to_arrow()\n",
    "    if current.num_rows == 0:\n",
    "        print(\"(empty table)\")\n",
    "        return\n",
    "    \n",
    "    df = current.to_pandas()\n",
    "    # Group by changeset\n",
    "    changeset_counts = df.groupby('changeset', dropna=False).size()\n",
    "    print(f\"\\nTotal records: {len(df)}\")\n",
    "    print(f\"Changesets: {changeset_counts.to_dict()}\")\n",
    "    \n",
    "    # Show deleted records count\n",
    "    deleted_count = df['content'].isna().sum()\n",
    "    if deleted_count > 0:\n",
    "        print(f\"üóëÔ∏è  Deleted records (content=None): {deleted_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d0dbbd",
   "metadata": {},
   "source": [
    "## Scenario 1: Initial Load into Empty Table\n",
    "\n",
    "Starting with an empty table, load initial records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f06700",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_snapshot = create_record_table([\n",
    "    {\"id\": \"rec001\", \"content\": \"First record\"},\n",
    "    {\"id\": \"rec002\", \"content\": \"Second record\"},\n",
    "    {\"id\": \"rec003\", \"content\": \"Third record\"},\n",
    "])\n",
    "\n",
    "changeset_id = store.snapshot_sync(initial_snapshot)\n",
    "print(f\"‚úÖ Initial load complete. Changeset ID: {changeset_id}\")\n",
    "\n",
    "current = display_table(\"Initial State\")\n",
    "display_changeset_summary()\n",
    "\n",
    "# Verify all records have the same changeset\n",
    "assert current.column(\"changeset\").to_pylist().count(changeset_id) == 3\n",
    "print(\"\\n‚úì All records share the same changeset_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803c61ea",
   "metadata": {},
   "source": [
    "## Scenario 2: Idempotent Sync (No Changes)\n",
    "\n",
    "Apply the same snapshot again. Should return `None` and make no changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c734bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_snapshot = create_record_table([\n",
    "    {\"id\": \"rec001\", \"content\": \"First record\"},\n",
    "    {\"id\": \"rec002\", \"content\": \"Second record\"},\n",
    "    {\"id\": \"rec003\", \"content\": \"Third record\"},\n",
    "])\n",
    "\n",
    "result = store.snapshot_sync(same_snapshot)\n",
    "\n",
    "if result is None:\n",
    "    print(\"‚úÖ No changes detected (idempotent)\")\n",
    "else:\n",
    "    print(f\"‚ùå Unexpected: changeset created: {result}\")\n",
    "\n",
    "display_table(\"After Idempotent Sync (should be unchanged)\")\n",
    "display_changeset_summary()\n",
    "\n",
    "# Verify no new records created\n",
    "assert current.num_rows == 3\n",
    "print(\"\\n‚úì Record count unchanged\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33448bef",
   "metadata": {},
   "source": [
    "## Scenario 3: Content Updates\n",
    "\n",
    "Update some existing records with different content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83e477",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_snapshot = create_record_table([\n",
    "    {\"id\": \"rec001\", \"content\": \"UPDATED first record\"},\n",
    "    {\"id\": \"rec002\", \"content\": \"Second record\"},  # unchanged\n",
    "    {\"id\": \"rec003\", \"content\": \"UPDATED third record\"},\n",
    "])\n",
    "\n",
    "changeset_id_2 = store.snapshot_sync(updated_snapshot)\n",
    "print(f\"‚úÖ Updates applied. Changeset ID: {changeset_id_2}\")\n",
    "\n",
    "current = display_table(\"After Content Updates\")\n",
    "display_changeset_summary()\n",
    "\n",
    "# Verify only changed records have new changeset\n",
    "records = current.to_pylist()\n",
    "rec001 = [r for r in records if r[\"id\"] == \"rec001\"][0]\n",
    "rec002 = [r for r in records if r[\"id\"] == \"rec002\"][0]\n",
    "rec003 = [r for r in records if r[\"id\"] == \"rec003\"][0]\n",
    "\n",
    "assert rec001[\"changeset\"] == changeset_id_2, \"rec001 should have new changeset\"\n",
    "assert rec002[\"changeset\"] == changeset_id, \"rec002 should retain old changeset (unchanged)\"\n",
    "assert rec003[\"changeset\"] == changeset_id_2, \"rec003 should have new changeset\"\n",
    "\n",
    "print(\"\\n‚úì Only changed records received new changeset_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b814f",
   "metadata": {},
   "source": [
    "## Scenario 4: Insertions\n",
    "\n",
    "Add new records to the snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_with_new = create_record_table([\n",
    "    {\"id\": \"rec001\", \"content\": \"UPDATED first record\"},\n",
    "    {\"id\": \"rec002\", \"content\": \"Second record\"},\n",
    "    {\"id\": \"rec003\", \"content\": \"UPDATED third record\"},\n",
    "    {\"id\": \"rec004\", \"content\": \"NEW fourth record\"},\n",
    "    {\"id\": \"rec005\", \"content\": \"NEW fifth record\"},\n",
    "])\n",
    "\n",
    "changeset_id_3 = store.snapshot_sync(snapshot_with_new)\n",
    "print(f\"‚úÖ Insertions applied. Changeset ID: {changeset_id_3}\")\n",
    "\n",
    "current = display_table(\"After Insertions\")\n",
    "display_changeset_summary()\n",
    "\n",
    "# Verify new records exist and have the new changeset\n",
    "records = current.to_pylist()\n",
    "rec004 = [r for r in records if r[\"id\"] == \"rec004\"][0]\n",
    "rec005 = [r for r in records if r[\"id\"] == \"rec005\"][0]\n",
    "\n",
    "assert rec004[\"changeset\"] == changeset_id_3\n",
    "assert rec005[\"changeset\"] == changeset_id_3\n",
    "assert current.num_rows == 5\n",
    "\n",
    "print(\"\\n‚úì New records inserted with correct changeset_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdab7b",
   "metadata": {},
   "source": [
    "## Scenario 5: Soft Deletes\n",
    "\n",
    "Remove records from the snapshot. They should be marked as deleted (`content=None`) rather than physically removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ce69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_with_deletions = create_record_table([\n",
    "    {\"id\": \"rec001\", \"content\": \"UPDATED first record\"},\n",
    "    {\"id\": \"rec002\", \"content\": \"Second record\"},\n",
    "    # rec003, rec004, rec005 are missing - should be deleted\n",
    "])\n",
    "\n",
    "changeset_id_4 = store.snapshot_sync(snapshot_with_deletions)\n",
    "print(f\"‚úÖ Deletions applied. Changeset ID: {changeset_id_4}\")\n",
    "\n",
    "current = display_table(\"After Deletions\")\n",
    "display_changeset_summary()\n",
    "\n",
    "# Verify deleted records have content=None\n",
    "records = current.to_pylist()\n",
    "rec003 = [r for r in records if r[\"id\"] == \"rec003\"][0]\n",
    "rec004 = [r for r in records if r[\"id\"] == \"rec004\"][0]\n",
    "rec005 = [r for r in records if r[\"id\"] == \"rec005\"][0]\n",
    "\n",
    "assert rec003[\"content\"] is None, \"rec003 should be soft-deleted\"\n",
    "assert rec004[\"content\"] is None, \"rec004 should be soft-deleted\"\n",
    "assert rec005[\"content\"] is None, \"rec005 should be soft-deleted\"\n",
    "assert rec003[\"changeset\"] == changeset_id_4\n",
    "assert rec004[\"changeset\"] == changeset_id_4\n",
    "assert rec005[\"changeset\"] == changeset_id_4\n",
    "\n",
    "print(\"\\n‚úì Deleted records marked with content=None\")\n",
    "print(\"‚úì All deleted records have the same changeset_id\")\n",
    "\n",
    "# Show deleted records separately\n",
    "print(\"\\nüóëÔ∏è  Deleted Records:\")\n",
    "deleted_records = [r for r in records if r[\"content\"] is None]\n",
    "for rec in deleted_records:\n",
    "    print(f\"  - {rec['id']} (changeset: {rec['changeset'][:8]}...)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0378e3bb",
   "metadata": {},
   "source": [
    "## Scenario 6: Undelete / Restore\n",
    "\n",
    "Restore a previously deleted record. This should update the existing deleted record (not create a duplicate)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8c795",
   "metadata": {},
   "source": [
    "## Scenario 7: Mixed Operations (Insert + Update + Delete)\n",
    "\n",
    "Apply a snapshot with all three operations simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_with_restore = create_record_table([\n",
    "    {\"id\": \"rec001\", \"content\": \"UPDATED first record\"},\n",
    "    {\"id\": \"rec002\", \"content\": \"Second record\"},\n",
    "    {\"id\": \"rec003\"},  # Deleting this one\n",
    "])\n",
    "\n",
    "changeset_id_5 = store.snapshot_sync(snapshot_with_restore)\n",
    "\n",
    "current = display_table(\"After Update\")\n",
    "display_changeset_summary()\n",
    "records = current.to_pylist()\n",
    "rec003 = records[2]  # Assuming sorted by id\n",
    "\n",
    "assert \"content\" not in rec003 or rec003[\"content\"] is None\n",
    "assert current.num_rows == 5, \"Total records should still be 5\"\n",
    "\n",
    "print(\"\\n‚úì Update successful\")\n",
    "print(f\"‚úì Total records: {current.num_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc91b27",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the complete behavior of `snapshot_sync`:\n",
    "\n",
    "### ‚úÖ What We Showed\n",
    "\n",
    "1. **Initial Load**: Populating an empty table\n",
    "2. **Idempotency**: Repeated syncs with identical data produce no changes\n",
    "3. **Updates**: Content changes are detected and applied\n",
    "4. **Insertions**: New records are added\n",
    "5. **Soft Deletes**: Missing records marked with `content=None` (not physically deleted)\n",
    "6. **Undelete/Restore**: Deleted records can be restored without creating duplicates\n",
    "7. **Mixed Operations**: Insert, update, and delete in a single sync\n",
    "8. **Namespace Isolation**: Only the specified namespace is affected\n",
    "9. **Query Methods**: Different ways to retrieve records (by changeset, active only, including deleted)\n",
    "\n",
    "### Key Differences from `incremental_update`\n",
    "\n",
    "| Feature | `snapshot_sync` | `incremental_update` |\n",
    "|---------|-----------------|----------------------|\n",
    "| **Deletions** | ‚úÖ Deletes missing records | ‚ùå Never deletes |\n",
    "| **Timestamps** | ‚ö†Ô∏è Writes them but doesn't check | ‚úÖ Required & enforced (newer only) |\n",
    "| **Use Case** | Full synchronization | Incremental harvesting |\n",
    "| **Data Protection** | None (overwrites freely) | Protects against timestamp regression |\n",
    "\n",
    "### When to Use Each Method\n",
    "\n",
    "- **Use `snapshot_sync`**: When you have a complete snapshot and want the table to match exactly (e.g., nightly full dumps, complete exports)\n",
    "- **Use `incremental_update`**: When harvesting changes incrementally where records may arrive out of order (e.g., OAI-PMH, event streams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a087e2b",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64065781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the demo table\n",
    "table.catalog.drop_table(f\"demo.{table_name}\")\n",
    "print(f\"‚úÖ Dropped table: {table_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalogue_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
