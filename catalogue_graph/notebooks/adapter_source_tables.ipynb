{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure AWS profile for local development\n",
    "%env AWS_PROFILE=platform-developer\n",
    "\n",
    "from adapters.ebsco.helpers import build_adapter_table as build_adapter_table_ebsco\n",
    "from adapters.axiell.helpers import build_adapter_table as build_adapter_table_axiell\n",
    "\n",
    "# If false will attempt to use a local Iceberg table instead of using the S3 Tables REST API\n",
    "USE_REST_API_TABLE = True\n",
    "\n",
    "# Load the Iceberg table via the S3 Tables Iceberg REST API\n",
    "ebsco_adapter_table = build_adapter_table_ebsco(use_rest_api_table=USE_REST_API_TABLE)\n",
    "axiell_adapter_table = build_adapter_table_axiell(use_rest_api_table=USE_REST_API_TABLE)\n",
    "print(f\"Adapter tables loaded\")\n",
    "\n",
    "print(ebsco_adapter_table)\n",
    "print(axiell_adapter_table)\n",
    "\n",
    "# Choose which adapter table to query\n",
    "table = axiell_adapter_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa6ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise each adapter table: total records + earliest/latest last_modified\n",
    "# Note: computing earliest/latest requires scanning the `last_modified` column and may take a while on large tables.\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.compute as pc\n",
    "\n",
    "\n",
    "def _table_summary(name: str, t):\n",
    "    # Count is usually metadata-driven (fast-ish), but can still take time depending on table/files.\n",
    "    count = t.scan().count()\n",
    "    \n",
    "    earliest = None\n",
    "    latest = None\n",
    "    try:\n",
    "        lm = t.scan(selected_fields=(\"last_modified\",)).to_arrow()[\"last_modified\"]\n",
    "        # Drop nulls if present\n",
    "        earliest = pc.min(lm).as_py()\n",
    "        latest = pc.max(lm).as_py()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not compute earliest/latest last_modified for {name}: {e}\")\n",
    "    \n",
    "    return {\n",
    "        \"table\": name,\n",
    "        \"records\": count,\n",
    "        \"earliest_last_modified\": earliest,\n",
    "        \"latest_last_modified\": latest,\n",
    "    }\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame(\n",
    "    [\n",
    "        _table_summary(\"ebsco_adapter_table\", ebsco_adapter_table),\n",
    "        _table_summary(\"axiell_adapter_table\", axiell_adapter_table),\n",
    "    ]\n",
    ").sort_values(\"table\")\n",
    "\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aaba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the first 10 data rows (excluding any projection to keep all columns)\n",
    "first_10 = table.scan(\n",
    "    selected_fields=(\"namespace\", \"id\", \"content\", \"changeset\", \"last_modified\"),\n",
    "    limit=10,\n",
    ").to_arrow()\n",
    "\n",
    "print(f\"Fetched {first_10.num_rows} rows\")\n",
    "display(first_10.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51244b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all rows using pyiceberg's row-level delete API only (no fallback).\n",
    "# Run the table-loading cell first so `table` is defined.\n",
    "\n",
    "# WARNING: This will irreversibly delete all data in the table!!!\n",
    "# DO NOT run this cell if you are not absolutely sure what you're doing.\n",
    "\n",
    "before_count = table.scan().count()\n",
    "print(f\"Rows before delete: {before_count}\")\n",
    "\n",
    "# with table.transaction() as tx:  # type: ignore[attr-defined]\n",
    "#     try:\n",
    "#         tx.delete(delete_filter=AlwaysTrue())  # type: ignore[attr-defined]\n",
    "#     except Exception as e:\n",
    "#         raise RuntimeError(\"Row-level delete failed.\") from e\n",
    "\n",
    "# after_count = table.scan().count()\n",
    "# print(f\"Rows after delete:  {after_count}\")\n",
    "# assert after_count == 0, \"Delete operation failed: table not empty\"\n",
    "# print(\"All rows deleted successfully via row-level delete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2880ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a record with a specific id\n",
    "record_id = \"collect:15101\"  # Replace with an actual record ID\n",
    "record = table.scan(\n",
    "    selected_fields=(\"namespace\", \"id\", \"content\"),\n",
    "    row_filter=f\"id = '{record_id}'\",\n",
    ").to_arrow()\n",
    "\n",
    "if record.num_rows == 0:\n",
    "    print(f\"No record found with id: {record_id}\")\n",
    "else:\n",
    "    print(f\"Record with id {record_id}:\")\n",
    "    try:\n",
    "        display(record.to_pandas())  # type: ignore[name-defined]\n",
    "    except Exception:\n",
    "        from pprint import pprint\n",
    "\n",
    "        pprint(record.to_pylist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc3572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the XML content of the record and pretty print it\n",
    "xml_value = record[\"content\"].to_pylist()[0]\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "root = ET.fromstring(xml_value)\n",
    "\n",
    "ET.indent(root)\n",
    "ET.dump(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c244dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the record and print the transformed output\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "from adapters.ebsco.steps.transformer import transform\n",
    "\n",
    "# (transformed_record, _) = transform(record_id, xml_value)\n",
    "# print(json.dumps(transformed_record[0].model_dump(), indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalogue_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
