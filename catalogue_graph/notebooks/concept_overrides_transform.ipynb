{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc87afe",
   "metadata": {},
   "source": [
    "# Concept Overrides Transformation\n",
    "\n",
    "This notebook documents the `ConceptOverrides` transformation, which allows for manual overrides of concept descriptions in our dataset. \n",
    "\n",
    "It outputs a transformed CSV after retrieving IIIF image urls from image ids, we may want to convert this into a script if we end up using it long term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b956841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "import json\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "from functools import lru_cache\n",
    "\n",
    "input_path = Path(\"./data/combined_overrides.csv\")\n",
    "output_path = Path(\"../src/ingestor/transformers/wellcome_collection_authority.csv\")\n",
    "\n",
    "API_BASE = \"https://api.wellcomecollection.org/catalogue/v2/images/\"\n",
    "\n",
    "expected_columns = {\n",
    "    \"conceptid\",\n",
    "    \"imageid1\",\n",
    "    \"imageid2\",\n",
    "    \"imageid3\",\n",
    "    \"imageid4\",\n",
    "    \"labeloverride\",\n",
    "    \"description\",\n",
    "}\n",
    "\n",
    "class ImageResolutionError(Exception):\n",
    "    \"\"\"Raised when an image ID cannot be resolved to a IIIF URL.\"\"\"\n",
    "    pass\n",
    "\n",
    "@lru_cache(maxsize=2048)\n",
    "def resolve_image_id(image_id: str) -> str:\n",
    "    \"\"\"Return IIIF Image API info.json URL for an image_id or raise.\n",
    "\n",
    "    Looks up the image in the API, finds the first DigitalLocation whose\n",
    "    locationType.id == 'iiif-image', and returns its 'url'.\n",
    "    Raises ImageResolutionError if it cannot be resolved.\n",
    "    \"\"\"\n",
    "    image_id = (image_id or \"\").strip()\n",
    "    if not image_id:\n",
    "        raise ImageResolutionError(\"Blank image_id\")\n",
    "    url = API_BASE + image_id\n",
    "    try:\n",
    "        with urllib.request.urlopen(url, timeout=10) as resp:  # nosec B310 (read-only public API)\n",
    "            if resp.status != 200:\n",
    "                raise ImageResolutionError(f\"HTTP {resp.status} for {image_id}\")\n",
    "            data = json.loads(resp.read().decode(\"utf-8\"))\n",
    "    except (urllib.error.URLError, urllib.error.HTTPError, TimeoutError, json.JSONDecodeError) as e:\n",
    "        raise ImageResolutionError(f\"Request/parse failed for {image_id}: {e}\") from e\n",
    "\n",
    "    locations = data.get(\"locations\") or []\n",
    "    for loc in locations:\n",
    "        try:\n",
    "            if (loc.get(\"locationType\") or {}).get(\"id\") == \"iiif-image\" and \"url\" in loc:\n",
    "                return loc[\"url\"]\n",
    "        except AttributeError:\n",
    "            continue\n",
    "    raise ImageResolutionError(f\"No iiif-image location for {image_id}\")\n",
    "\n",
    "unresolved_ids = set()\n",
    "\n",
    "with input_path.open(newline=\"\", encoding=\"utf-8\") as in_f:\n",
    "    reader = csv.DictReader(in_f)\n",
    "\n",
    "    # Normalize fieldnames (strip whitespace + BOM) to avoid false missing-column errors\n",
    "    raw_fieldnames = reader.fieldnames or []\n",
    "    normalized_fieldnames = [fn.strip().lstrip(\"\\ufeff\") for fn in raw_fieldnames]\n",
    "    fieldname_map = dict(zip(raw_fieldnames, normalized_fieldnames))\n",
    "\n",
    "    if normalized_fieldnames != raw_fieldnames:\n",
    "        print(\"Normalized header names:\")\n",
    "        for before, after in zip(raw_fieldnames, normalized_fieldnames):\n",
    "            if before != after:\n",
    "                print(f\"  '{before}' -> '{after}'\")\n",
    "\n",
    "    missing = expected_columns - set(normalized_fieldnames)\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            \"Input CSV is missing expected columns after normalization: \"\n",
    "            f\"{missing}. Found: {normalized_fieldnames}\"\n",
    "        )\n",
    "\n",
    "    with output_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as out_f:\n",
    "        fieldnames = [\"id\", \"label\", \"description\", \"image_url\"]\n",
    "        writer = csv.DictWriter(out_f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            # Re-key the row using normalized names\n",
    "            norm_row = {fieldname_map.get(k, k): v for k, v in row.items()}\n",
    "            image_ids = [\n",
    "                (norm_row.get(col) or \"\").strip()\n",
    "                for col in (\"imageid1\", \"imageid2\", \"imageid3\", \"imageid4\")\n",
    "            ]\n",
    "            image_ids = [iid for iid in image_ids if iid]  # drop blanks\n",
    "\n",
    "            resolved_urls = []\n",
    "            for iid in image_ids:\n",
    "                try:\n",
    "                    resolved_urls.append(resolve_image_id(iid))\n",
    "                except ImageResolutionError as e:\n",
    "                    unresolved_ids.add(iid)\n",
    "                    # omit this ID from the output\n",
    "                    continue\n",
    "\n",
    "            writer.writerow(\n",
    "                {\n",
    "                    \"id\": (norm_row.get(\"conceptid\") or \"\").strip(),\n",
    "                    \"label\": (norm_row.get(\"labeloverride\") or \"\").strip(),\n",
    "                    \"description\": (norm_row.get(\"description\") or \"\").strip(),\n",
    "                    \"image_url\": \"||\".join(resolved_urls),\n",
    "                }\n",
    "            )\n",
    "\n",
    "if unresolved_ids:\n",
    "    raise ImageResolutionError(\n",
    "        f\"Failed to resolve {len(unresolved_ids)} image IDs; they were omitted: \"\n",
    "        + \", \".join(sorted(unresolved_ids))\n",
    "    )\n",
    "\n",
    "print(f\"Wrote transformed CSV to {output_path.resolve()}\")\n",
    "\n",
    "# Preview first 5 rows of the transformed file\n",
    "with output_path.open(newline=\"\", encoding=\"utf-8\") as f:\n",
    "    preview_reader = csv.DictReader(f)\n",
    "    print(\"Preview:\")\n",
    "    for r in islice(preview_reader, 5):\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b62a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catalogue_graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
