{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9a27087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Start with running:\n",
    "# docker-compose up -d\n",
    "\n",
    "ES_URL = \"http://localhost:9200\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6754f223",
   "metadata": {},
   "source": [
    "## Check Elasticsearch is Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(f\"{ES_URL}/_cluster/health\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9be3c3",
   "metadata": {},
   "source": [
    "## Start Trial License\n",
    "\n",
    "ML features require a trial or paid license."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2fd06f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial license: {'acknowledged': True, 'trial_was_started': True, 'type': 'trial'}\n",
      "Waiting for ML indices to be ready...\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(f\"{ES_URL}/_license/start_trial?acknowledge=true\")\n",
    "print(f\"Trial license: {response.json()}\")\n",
    "\n",
    "# Wait longer for ML indices to initialize\n",
    "print(\"Waiting for ML indices to be ready...\")\n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757021dc",
   "metadata": {},
   "source": [
    "## Wait for Cluster Ready\n",
    "\n",
    "Wait for all shards to be active before importing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d929c70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster and ML indices are ready!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Wait for cluster to be green and ML indices ready\n",
    "for i in range(60):\n",
    "    response = requests.get(f\"{ES_URL}/_cluster/health\")\n",
    "    health = response.json()\n",
    "    \n",
    "    # Check for ML indices specifically\n",
    "    ml_response = requests.get(f\"{ES_URL}/.ml-inference-*/_recovery\")\n",
    "    ml_ready = ml_response.status_code == 200\n",
    "    \n",
    "    if health['status'] == 'green' and health['initializing_shards'] == 0 and ml_ready:\n",
    "        print(\"Cluster and ML indices are ready!\")\n",
    "        break\n",
    "    \n",
    "    status_info = f\"status={health['status']}, initializing={health['initializing_shards']}, ml_indices={ml_ready}\"\n",
    "    print(f\"Waiting for cluster... {status_info}\")\n",
    "    time.sleep(3)\n",
    "else:\n",
    "    print(\"Warning: Cluster may not be fully ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af611",
   "metadata": {},
   "source": [
    "## Import Model from Hugging Face\n",
    "\n",
    "Import msmarco-MiniLM-L12-cos-v5 model using Eland. This will download the model, convert it to TorchScript, and upload to Elasticsearch.\n",
    "\n",
    "**This may take several minutes on first run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d1f86a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 14:05:26,808 INFO : Establishing connection to Elasticsearch\n",
      "2026-01-09 14:05:26,841 INFO : Connected to cluster named 'docker-cluster' (version: 8.18.0)\n",
      "2026-01-09 14:05:26,842 INFO : Loading HuggingFace transformer tokenizer and model 'sentence-transformers/msmarco-MiniLM-L12-cos-v5'\n",
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
      "2026-01-09 14:05:30,078 WARNING : `SentenceTransformer._target_device` has been removed, please use `SentenceTransformer.device` instead.\n",
      "2026-01-09 14:05:30,078 WARNING : `SentenceTransformer._target_device` has been removed, please use `SentenceTransformer.device` instead.\n",
      "/Users/agnesgaroux/wellcome/catalogue-pipeline/semantic-search-local/.venv/lib/python3.12/site-packages/transformers/modeling_attn_mask_utils.py:196: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  inverted_mask = torch.tensor(1.0, dtype=dtype) - expanded_mask\n",
      "2026-01-09 14:05:30,483 WARNING : `SentenceTransformer._target_device` has been removed, please use `SentenceTransformer.device` instead.\n",
      "2026-01-09 14:05:30,483 WARNING : `SentenceTransformer._target_device` has been removed, please use `SentenceTransformer.device` instead.\n",
      "2026-01-09 14:05:31,538 INFO : Creating model with id 'sentence-transformers__msmarco-minilm-l12-cos-v5'\n",
      "2026-01-09 14:05:32,080 INFO : Uploading model definition\n",
      "100%|██████████| 127/127 [00:05<00:00, 21.92 parts/s]\n",
      "2026-01-09 14:05:37,874 INFO : Uploading model vocabulary\n",
      "2026-01-09 14:05:37,934 INFO : Starting model deployment\n",
      "2026-01-09 14:05:41,520 INFO : Model successfully imported with id 'sentence-transformers__msmarco-minilm-l12-cos-v5'\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "eland_import_hub_model \\\n",
    "  --url http://localhost:9200 \\\n",
    "  --hub-model-id sentence-transformers/msmarco-MiniLM-L12-cos-v5 \\\n",
    "  --task-type text_embedding \\\n",
    "  --start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180719f",
   "metadata": {},
   "source": [
    "## Check Model Status\n",
    "\n",
    "Verify the model was imported and started successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "284115a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: sentence-transformers__msmarco-minilm-l12-cos-v5\n",
      "Deployment state: started\n",
      "Allocations: 1\n"
     ]
    }
   ],
   "source": [
    "model_id = \"sentence-transformers__msmarco-minilm-l12-cos-v5\"\n",
    "\n",
    "response = requests.get(f\"{ES_URL}/_ml/trained_models/{model_id}/_stats\")\n",
    "stats = response.json()\n",
    "\n",
    "if \"trained_model_stats\" in stats and len(stats[\"trained_model_stats\"]) > 0:\n",
    "    model_stats = stats[\"trained_model_stats\"][0]\n",
    "    print(f\"Model ID: {model_stats['model_id']}\")\n",
    "    print(f\"Deployment state: {model_stats.get('deployment_stats', {}).get('state', 'not deployed')}\")\n",
    "    print(f\"Allocations: {model_stats.get('deployment_stats', {}).get('allocation_status', {}).get('allocation_count', 0)}\")\n",
    "else:\n",
    "    print(\"Model not found or not deployed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedec7d",
   "metadata": {},
   "source": [
    "## Create Inference Endpoint\n",
    "\n",
    "Create an inference endpoint that uses our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71638c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inference_id': 'msmarco-embeddings', 'task_type': 'text_embedding', 'service': 'elasticsearch', 'service_settings': {'num_allocations': 1, 'num_threads': 1, 'model_id': 'sentence-transformers__msmarco-minilm-l12-cos-v5', 'dimensions': 384, 'similarity': 'cosine', 'element_type': 'float'}, 'chunking_settings': {'strategy': 'sentence', 'max_chunk_size': 250, 'sentence_overlap': 1}}\n"
     ]
    }
   ],
   "source": [
    "inference_config = {\n",
    "    \"service\": \"elasticsearch\",\n",
    "    \"service_settings\": {\n",
    "        \"model_id\": model_id,\n",
    "        \"num_allocations\": 1,\n",
    "        \"num_threads\": 1\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.put(\n",
    "    f\"{ES_URL}/_inference/text_embedding/msmarco-embeddings\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    json=inference_config\n",
    ")\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d1f8c6",
   "metadata": {},
   "source": [
    "## Create Index with Semantic Search\n",
    "\n",
    "Create the works index with semantic_text fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a5af504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "{\n",
      "  \"acknowledged\": true,\n",
      "  \"shards_acknowledged\": true,\n",
      "  \"index\": \"works-semantic-local\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open('mappings.works_semantic.json', 'r') as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "response = requests.put(\n",
    "    f\"{ES_URL}/works-semantic-local\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    json={\"mappings\": mappings}\n",
    ")\n",
    "\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75473e74",
   "metadata": {},
   "source": [
    "## Test with a Sample Document\n",
    "\n",
    "Index a test document to verify everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bc0d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 201\n",
      "{\n",
      "  \"_index\": \"works-semantic-local\",\n",
      "  \"_id\": \"test-001\",\n",
      "  \"_version\": 1,\n",
      "  \"result\": \"created\",\n",
      "  \"_shards\": {\n",
      "    \"total\": 2,\n",
      "    \"successful\": 1,\n",
      "    \"failed\": 0\n",
      "  },\n",
      "  \"_seq_no\": 0,\n",
      "  \"_primary_term\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "test_doc = {\n",
    "    \"id\": \"test-001\",\n",
    "    \"title\": \"A Brief History of Time\",\n",
    "    \"titleSemantic\": \"A Brief History of Time\",\n",
    "    \"description\": \"Stephen Hawking explores the nature of the universe, black holes, and the theory of relativity.\",\n",
    "    \"descriptionSemantic\": \"Stephen Hawking explores the nature of the universe, black holes, and the theory of relativity.\"\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{ES_URL}/works-semantic-local/_doc/test-001\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    json=test_doc\n",
    ")\n",
    "\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea760dc4",
   "metadata": {},
   "source": [
    "## Test Semantic Search\n",
    "\n",
    "Query using semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eedc419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "\n",
      "Found 1 results\n",
      "\n",
      "Score: 0.58017063\n",
      "Title: A Brief History of Time\n",
      "Description: Stephen Hawking explores the nature of the universe, black holes, and the theory of relativity....\n"
     ]
    }
   ],
   "source": [
    "# Give ES a moment to index\n",
    "time.sleep(2)\n",
    "\n",
    "query = {\n",
    "    \"query\": {\n",
    "        \"semantic\": {\n",
    "            \"field\": \"titleSemantic\",\n",
    "            \"query\": \"books about physics and cosmology\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(\n",
    "    f\"{ES_URL}/works-semantic-local/_search\",\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    json=query\n",
    ")\n",
    "\n",
    "print(f\"Status: {response.status_code}\")\n",
    "results = response.json()\n",
    "print(f\"\\nFound {results['hits']['total']['value']} results\")\n",
    "for hit in results['hits']['hits']:\n",
    "    print(f\"\\nScore: {hit['_score']}\")\n",
    "    print(f\"Title: {hit['_source']['title']}\")\n",
    "    print(f\"Description: {hit['_source']['description'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa5fae4",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now you're ready to:\n",
    "1. Load your full works snapshot\n",
    "2. Experiment with different queries\n",
    "3. Compare semantic vs keyword search results\n",
    "4. Try hybrid queries combining both approaches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic-search-local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
